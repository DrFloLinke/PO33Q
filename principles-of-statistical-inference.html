<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Principles of Statistical Inference |  PO33Q: Determinants of Democracy –   Analysing Emergence, Survival, and Fall</title>
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Principles of Statistical Inference |  PO33Q: Determinants of Democracy –   Analysing Emergence, Survival, and Fall">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Principles of Statistical Inference |  PO33Q: Determinants of Democracy –   Analysing Emergence, Survival, and Fall">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Lexend-0.4.10/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
<meta name="description" content="Starting to write this, I am tackling the interesting task of condensing four weeks’ worth of material of my introductory quantitative module into a few paragraphs. But a brief overview of...">
<meta property="og:description" content="Starting to write this, I am tackling the interesting task of condensing four weeks’ worth of material of my introductory quantitative module into a few paragraphs. But a brief overview of...">
<meta name="twitter:description" content="Starting to write this, I am tackling the interesting task of condensing four weeks’ worth of material of my introductory quantitative module into a few paragraphs. But a brief overview of...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title=""><p><img src="images/Crest_white.png" width="75" style="display:block; margin:auto; margin-bottom:3em;"> PO33Q: Determinants of Democracy – <br> Analysing Emergence, Survival, and Fall</p></a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="website-features.html">Website Features</a></li>
<li><a class="" href="accessibility.html">Accessibility</a></li>
<li class="book-part">Week 1</li>
<li><a class="" href="introduction-to-r.html">Introduction to R</a></li>
<li><a class="" href="homework-for-week-2.html">Homework for Week 2</a></li>
<li><a class="" href="glossary.html">Glossary</a></li>
<li><a class="" href="flashcards.html">Flashcards</a></li>
<li class="book-part">Week 2</li>
<li><a class="active" href="principles-of-statistical-inference.html">Principles of Statistical Inference</a></li>
<li><a class="" href="linear-regression---theory.html">Linear Regression - Theory</a></li>
<li><a class="" href="linear-regression-application.html">Linear Regression – Application</a></li>
<li><a class="" href="homework-for-week-3.html">Homework for Week 3</a></li>
<li><a class="" href="glossary-1.html">Glossary</a></li>
<li><a class="" href="flashcards-1.html">Flashcards</a></li>
<li class="book-part">Week 3</li>
<li><a class="" href="probit---theory.html">Probit - Theory</a></li>
<li><a class="" href="probit-application.html">Probit – Application</a></li>
<li><a class="" href="exercises.html">Exercises</a></li>
<li><a class="" href="homework-for-week-4.html">Homework for Week 4</a></li>
<li><a class="" href="glossary-2.html">Glossary</a></li>
<li><a class="" href="flashcards-2.html">Flashcards</a></li>
<li class="book-part">Week 4</li>
<li><a class="" href="missing-data.html">Missing Data</a></li>
<li><a class="" href="model-building.html">Model Building</a></li>
<li><a class="" href="homework-for-week-5.html">Homework for Week 5</a></li>
<li><a class="" href="glossary-3.html">Glossary</a></li>
<li><a class="" href="flashcards-3.html">Flashcards</a></li>
<li class="book-part">Week 5</li>
<li><a class="" href="consolidation.html">Consolidation</a></li>
<li><a class="" href="exercises-1.html">Exercises</a></li>
<li><a class="" href="homework-for-week-7.html">Homework for Week 7</a></li>
<li><a class="" href="glossary-4.html">Glossary</a></li>
<li><a class="" href="flashcards-4.html">Flashcards</a></li>
<li class="book-part">Week 7</li>
<li><a class="" href="markov-transition-models.html">Markov Transition Models</a></li>
<li><a class="" href="model-fit-in-binary-response-models.html">Model Fit in Binary Response Models9</a></li>
<li><a class="" href="joint-estimation-of-emergence-and-survival.html">Joint Estimation of Emergence and Survival</a></li>
<li><a class="" href="exercises-2.html">Exercises</a></li>
<li><a class="" href="homework-for-week-8.html">Homework for Week 8</a></li>
<li><a class="" href="glossary-5.html">Glossary</a></li>
<li><a class="" href="flashcards-5.html">Flashcards</a></li>
<li class="book-part">Downloads</li>
<li><a class="" href="downloads.html">Downloads</a></li>
<li class="book-part">Glossary</li>
<li><a class="" href="glossary-6.html">Glossary</a></li>
<li class="book-part">List of References</li>
<li><a class="" href="list-of-references.html">List of References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><script src="sidebar-link.js"></script><div id="principles-of-statistical-inference" class="section level1 unnumbered">
<h1>Principles of Statistical Inference<a class="anchor" aria-label="anchor" href="#principles-of-statistical-inference"><i class="fas fa-link"></i></a>
</h1>
<p>Starting to write this, I am tackling the interesting task of condensing four weeks’ worth of material of my introductory quantitative module into a few paragraphs. But a brief overview of statistical inference and significance tests is essential for you to understand the interpretation of the methods we are going to explore. So let’s start with probability distributions.</p>
<hr>
<div id="probability-distributions" class="section level2 unnumbered">
<h2>Probability Distributions<a class="anchor" aria-label="anchor" href="#probability-distributions"><i class="fas fa-link"></i></a>
</h2>
<p>The term <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">probability distribution</a></span> sounds fancy, but really only implies that we are assessing the relative frequency with which a particular value occurs. So, for example, if I have six History students on the module, and four PAIS students, then the <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-1.html">probability</a></span> of being a PAIS student is 40%. For categorical data, such as this, we can assign a probability to each category. But for continuous variables, such as the Polity V score, or per capita GDP this no longer works. Instead, we assign probabilities to an interval of numbers. In the following graph, I am putting the values of such a continuous variable on the x-axis, and then draw a curve over this which indicates the probability distribution for these values.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:probability"></span>
<img src="images/Week%202/prob1.png" alt="\label{fig:probability}Probability Distribution for a Continuous Variable" width="60%"><p class="caption">
Figure 7: Probability Distribution for a Continuous Variable
</p>
</div>
<p>In this graph, the values on the x-axis between alpha and beta have a probability of occurring that is equal to the orange area under the curve. This curve is bell-shaped, and symmetrical around the mean of the variable x, and is known as the <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">normal distribution</a></span>. The beauty of this distribution is that the amount of probability that is contained in an interval around the mean depends solely on the number of standard deviations, denoted as <span class="math inline">\(\sigma\)</span>, of the variable x. So, for example, if I travel one standard deviation to the left and to the right from the mean, I will always have 68% of the area under the distribution in this interval.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:righttail"></span>
<img src="images/Week%202/prob2.png" alt="\label{fig:righttail}Probability within one Standard Deviation" width="60%"><p class="caption">
Figure 8: Probability within one Standard Deviation
</p>
</div>
<p>For two standard deviations, this is equivalent to 96% and for three standard deviations 99.9%. Schematically this looks as follows:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:normal"></span>
<img src="images/Week%202/prob3.png" alt="\label{fig:normal}Probabilities under the Normal Distribution" width="60%"><p class="caption">
Figure 9: Probabilities under the Normal Distribution
</p>
</div>
<p>The total area under the probability distribution is equal to 100%. So, if the orange area in Figure <a href="principles-of-statistical-inference.html#fig:righttail">8</a> is equal to 68%, then the remaining area must be 32%. As this area is split equally into a left and a right side, the area on the right must be 16%. This is what is known as a right-tail probability. Here it is the probability beyond 1 standard deviation, or <span class="math inline">\(1 \sigma\)</span>.</p>
<p>This means that if we know how many standard deviations away from the mean of the distribution a value falls, we can make a statement on how likely it would be to observe a value that is higher than this value. For example, if I know the distribution of marks on a module, this would allow me to state how likely it was to achieve a First, or a mark of higher than 70. Assume that the average of an assessment was 63, and the standard deviation 9. Then the difference between the mean and the value we are interested in is equal to 70-63=7. To express this distance in units of standard deviations, we now divide 7 by 9, and obtain something that is called a z-score:</p>
<p><span class="math display">\[\begin{equation}
z=\frac{\text{Observation} - \text{Mean}}{\text{Standard Deviation}}
\end{equation}\]</span></p>
<p>In our case, z would be equal to 7/9, or 0.7777778. You can look this value up in a <a href="files/Downloads/Statistical%20Tables.pdf">z-table</a> which lists the right-tail probability for all conceivable values of z. For z=0.78 it returns a probability of 21.77%. With a mean of 63 and standard deviation of 9,the probability of scoring a First would be 21.77%.</p>
<p>This all works fine, so long as we are dealing with the <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">population</a></span>. Sadly, we rarely have access to the population in the social sciences, however. Surveys, for example, are usually conducted for a small representative sub-group of the population, a <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">sample</a></span>. So, how do we make statements about the population if we only have access to a sample? The answer is: with a sampling distribution.</p>
<div id="sampling-distributions" class="section level3 unnumbered">
<h3>Sampling Distributions<a class="anchor" aria-label="anchor" href="#sampling-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>Whenever we draw a sample from a population, the values we draw will vary. Therefore, also the mean of these values will vary each time. Imagine I draw a sample of 5 students from a seminar group, time and time again, and each time I calculate the average age of these 5 students. Sometimes the average will be high, sometimes it will be low, but – and here comes the magic – the value that will come up most often in these samples is the true mean of the population (all students in the seminar). We call this population value a <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">parameter</a></span>.</p>
<p>If we arrange all of the sample means we have obtained from sampling again and again, these means will form a distribution in their own right, the sampling distribution. This has the true population mean (let’s denote this as <span class="math inline">\(\mu\)</span>) in its centre. In Figure <a href="principles-of-statistical-inference.html#fig:sampling">10</a>, for example, I have simulated a population with a mean of zero, and have drawn 9000 samples from this population, each with 30 observations. As you can see, the distribution of means of each of these 9000 samples forms a normal distribution which has zero, the population mean, at its centre.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sampling"></span>
<img src="prob3.png" alt="\label{fig:sampling}Sampling Distribution" width="75%"><p class="caption">
Figure 10: Sampling Distribution
</p>
</div>
<p>So, we know the mean of the sampling distribution, but what about its standard deviation? We could of course take samples repeatedly from the population and calculate it, but that is wasteful. Instead, we estimate it by dividing the standard deviation of the one sample we usually have by the square root of the sample size. The result is the so-called <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">standard error</a></span>, denoted as “se”, the standard deviation of the sampling distribution.</p>
<p><span class="math display">\[\begin{equation}
se=\frac{s}{\sqrt{n}}
\end{equation}\]</span></p>
<p>where s is the sample standard deviation and n is the sample size.</p>
<p>The sample standard deviation varies with each sample we draw, however, and this introduces uncertainty into our analysis. The normal distribution cannot deal with this uncertainty, and so we have to abandon it in favour of the <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">t-distribution</a></span>.</p>
</div>
<div id="the-t-distribution" class="section level3 unnumbered">
<h3>The t-Distribution<a class="anchor" aria-label="anchor" href="#the-t-distribution"><i class="fas fa-link"></i></a>
</h3>
<p>The t-distribution is also bell-shaped and symmetrical, centered around a fixed mean of zero. But, crucially, its shape is not static, but depends on the number of <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">degrees of freedom</a></span>. Degrees of freedom are constraints on the estimation process that reflect the number of independent pieces of information available. In our case, the constraint arises from estimating the population standard deviation <span class="math inline">\(\sigma\)</span> using the sample standard deviation, <span class="math inline">\(s\)</span>. For a single sample, the degrees of freedom are defined as n-1, where n is the sample size. Depending on these degrees of freedom, the t-distribution becomes wider or narrower, expressing the uncertainty we are incurring from working with a sample of a particular size. You can see in Figure <a href="principles-of-statistical-inference.html#fig:t">11</a> that with increasing sample size the t-distribution becomes narrower and narrower, until – for an infinite sample size – it is equivalent to the normal distribution again. The smaller the sample size, the wider the t-distribution becomes. This means that as the sample size decreases we need to travel more standard deviations away from the mean in order to obtain a certain probability. More on this below under “Confidence Intervals”.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:t"></span>
<img src="images/Week%202/tdis.png" alt="\label{fig:t}Comparison of t-Distributions" width="85%"><p class="caption">
Figure 11: Comparison of t-Distributions
</p>
</div>
<p>Using the sampling distribution, we can create a range of values that we think the true population value (like the average) falls into. This range is called a <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">confidence interval</a></span>. For example, a 95% confidence interval means that if we took many random samples and made a new interval each time, about 95% of those intervals would contain the true value.</p>
<hr>
</div>
</div>
<div id="confidence-intervals" class="section level2 unnumbered">
<h2>Confidence Intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals"><i class="fas fa-link"></i></a>
</h2>
<p>How do we construct confidence intervals? We start by setting the <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">confidence level</a></span> — the proportion of confidence intervals, constructed from repeated random samples of the same population using the same method, that are expected to contain the true population parameter. It is denoted by <span class="math inline">\(1 - \alpha\)</span>, where <span class="math inline">\(\alpha\)</span> is the <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">significance level</a></span>. For example, a 95% confidence level implies that 95% of such intervals would contain the true parameter in the long run.</p>
<p>Because the interval is constructed from a sample, we use the sampling distribution of the sample mean. We place the sample mean at the center of this distribution and treat it as our point estimate of the unknown population mean. To establish an interval around this estimate corresponding to the desired confidence level, we determine how many standard errors we must move to the left and right. Whereas under the normal distribution this was the z-score, under the t-score this number is called the <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">t-score</a></span>, which can be found using a <a href="files/Downloads/Statistical%20Tables.pdf">statistical table</a>.</p>
<p>The appropriate t-score depends on the sample size (or the degrees of freedom, to be more precise). As hinted above, for smaller samples the t-distribution is wider, so we need to travel further away from the mean to achieve the same level of confidence than we would with a larger sample and a narrower distribution. For example, to construct a 95% confidence interval, we would use a t-score of approximately 2.306 for a sample of 9, but only 2.045 for a sample of 30.</p>
<p>As an example, reconsider our fictitious assessment with an average of 63, and the standard deviation 9. I used this for a probability statement in a population earlier, but now assume this is based on a sample of 15 students from a much larger module. Within which boundaries do we believe the parameter to fall with 95% confidence?</p>
<p>As a first step, we calculate the standard error:</p>
<p><span class="math display">\[\begin{equation}
se=\frac{s}{\sqrt{n}}= \frac{9}{\sqrt{15}} = 2.32379
\end{equation}\]</span></p>
<p>As we have 15 observations, we have 14 degrees of freedom (n-1) which corresponds to a t-score of 2.145. We can thus state that with 95% confidence the parameter, <span class="math inline">\(\mu\)</span>, falls between 58.02 and 67.98.</p>
<p><span class="math display">\[\begin{align}
\bar{y} - t \cdot se \le \;\; &amp;\mu \; \le \bar{y} - t \cdot se \\\\
63- 2.145 \cdot 2.32379 \le \;\; &amp;\mu \; \le 63 + 2.145 \cdot 2.32379 \\\\
58.01547 \le \;\; &amp;\mu \; \le 67.98453
\end{align}\]</span></p>
<p>where <span class="math inline">\(\bar{y}\)</span> is the average in the sample<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;For the pedants: I am aware this should read &lt;span class="math inline"&gt;\(\bar{y} - t_{\alpha/2} \cdot se \le \mu \le \bar{y} - t_{\alpha/2} \cdot se\)&lt;/span&gt;, but I have left the subscripts out to make it less confusing here.&lt;/p&gt;'><sup>4</sup></a>.</p>
<p>We will come back to confidence intervals in the context of regression analysis. Let us now look at significance tests.</p>
<hr>
</div>
<div id="tests-of-statistical-significance" class="section level2 unnumbered">
<h2>Tests of Statistical Significance<a class="anchor" aria-label="anchor" href="#tests-of-statistical-significance"><i class="fas fa-link"></i></a>
</h2>
<p>As you know from the lecture last week, in the social sciences we generally test whether we can explain behaviour or some kind of phenomenon through a particular theory. In practical terms this means that we distill the theory into testable statements, called hypotheses. Take this hypothesis, for example: The average level of democracy in the Middle East is statistically different from that of Europe. In this statement, we are no longer interested in establishing an interval of numbers within which we believe the average level of democracy in the Middle East to fall, but we are comparing it with a particular value, or point: the level of democracy in Europe. This kind of assessment is called a <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">significance test</a></span>.</p>
<p>Every significance test has two hypotheses, an alternative, and a null-hypothesis. The alternative hypothesis is the one I already stated:</p>
 
<center>
H<span class="math inline">\(_\text{A}\)</span>: The average level of democracy in the Middle East is statistically different from that of Europe.
</center>
<p> 
 </p>
<p>The null-hypothesis always represents no effect. In our case the region would have no impact on the democracy level, and the Polity V score of Europe and the Middle East would be identical.</p>
 
<center>
H<span class="math inline">\(_0\)</span>: The average level of democracy in the Middle East is the same as in Europe.
</center>
<p> 
 </p>
<p>The average Polity V score in the Middle East was -2.8 in 2015 with a standard deviation of 7.07 across 15 countries. The average Polity V score for Europe in the same year was 8.7.</p>
<div class="baser">
<details><summary>
How to obtain these values
</summary><div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">me</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">world</span>, <span class="va">countrycode</span><span class="op">==</span><span class="st">"BHR"</span> <span class="op">|</span> <span class="co">#Bahrain</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"CYP"</span> <span class="op">|</span> <span class="co">#Cyprus</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"EGY"</span> <span class="op">|</span> <span class="co">#Egypt</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"IRN"</span> <span class="op">|</span> <span class="co">#Iran</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"IRQ"</span> <span class="op">|</span> <span class="co">#Iraq</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"ISR"</span> <span class="op">|</span> <span class="co">#Israel</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"JOR"</span> <span class="op">|</span> <span class="co">#Jordan</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"KWT"</span> <span class="op">|</span> <span class="co">#Kuwait</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"LBN"</span> <span class="op">|</span> <span class="co">#Lebanon</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"OMN"</span> <span class="op">|</span> <span class="co">#Oman</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"QAT"</span> <span class="op">|</span> <span class="co">#Qatar</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"SAU"</span> <span class="op">|</span> <span class="co">#Saudi Arabia</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"ARE"</span> <span class="op">|</span> <span class="co">#UAE</span></span>
<span>                    <span class="va">countrycode</span><span class="op">==</span><span class="st">"YEM"</span>   <span class="co">#Yemen</span></span>
<span>             <span class="op">)</span></span>
<span></span>
<span><span class="va">me_15</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">me</span>, <span class="va">year</span><span class="op">==</span><span class="fl">2015</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">me_15</span><span class="op">$</span><span class="va">polity5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">me_15</span><span class="op">$</span><span class="va">polity5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">world</span><span class="op">$</span><span class="va">un_region_name</span></span>
<span></span>
<span><span class="va">europe</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">world</span>, <span class="va">un_region_name</span><span class="op">==</span><span class="st">"Southern Europe"</span><span class="op">|</span>  </span>
<span>                   <span class="va">un_region_name</span><span class="op">==</span><span class="st">"Western Europe"</span> <span class="op">|</span> </span>
<span>                   <span class="va">un_region_name</span><span class="op">==</span><span class="st">"Eastern Europe"</span> <span class="op">|</span></span>
<span>                   <span class="va">un_region_name</span><span class="op">==</span><span class="st">"Northern Europe"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">europe_15</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">europe</span>, <span class="va">year</span><span class="op">==</span><span class="fl">2015</span><span class="op">)</span>          </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">europe_15</span><span class="op">$</span><span class="va">polity5</span>, na.rm<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">me_15</span><span class="op">$</span><span class="va">gdppc</span>, mu<span class="op">=</span><span class="fl">8.7</span>,  </span>
<span>       data<span class="op">=</span><span class="va">me_15</span><span class="op">)</span></span></code></pre></div>
</details>
</div>
<p>In order to ascertain whether the observed value of -2.8 is statistically different from the null-hypothesis value, 8.7, we need to make a probability statement. To be precise, we need to quantify the probability of observing a value that is more extreme than than one we have already observed if the null hypothesis was true. If this probability is small, then the value we have can be regarded as highly unusual and we can conclude that it is statistically different from the null-hypothesis value. This probability of observing a value more extreme than the one we have observed, assuming the null hypothesis is true, is the <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">p-value</a></span>.</p>
<p>Usually, we want the p-value to be quite small, either 5% or 1%. R will obtain this for us, but so you know what happens behind the scenes, here is a quick summary. We place the null hypothesis into the centre of a sampling distribution, effectively pretending that this is our population parameter. In other words, we assume that the null hypothesis is true. Now we look at where in relation to this null hypothesis value our observed value falls. We are then able to calculate the distance between the observed value and the null-hypothesis value in units of standard error. This is equivalent to the t-value, our <span class="gls"><a href="https://drfloreiche.github.io/PO33Q/glossary-2.html">test statistic</a></span>. We calculate it as follows:</p>
<p><span class="math display">\[\begin{equation}
t = \frac{\bar{y} - \mu_{0}}{se}, \quad \text{where} \, se = \frac{s}{\sqrt{n}}
\end{equation}\]</span></p>
<p>In our example:</p>
<p><span class="math display">\[\begin{equation}
t = \frac{-2.8 - 8.7}{1.826243} = -6.297081, \quad \text{where} \, se = \frac{7.07301}{\sqrt{15}}
\end{equation}\]</span></p>
<p>This places us quite far out into the tails of the t-distribution (see Figure <a href="principles-of-statistical-inference.html#fig:p">12</a>), and as such the probability of observing a value more extreme is very small. Hence, we can regard our observed value of -2.8 as unusual and conclude the the average democracy level in the Middle East is statistically different from that of Europe. The precise p-value for this is 0.001283, well below our desired significance level of 5%.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:p"></span>
<img src="images/Week%202/sigtest.png" alt="\label{fig:p}The p-Value" width="70%"><p class="caption">
Figure 12: The p-Value
</p>
</div>
<p>I have displayed this here as a two-sided test. We did not specify whether we expect the level of democracy in the Middle East to be higher or lower than in Europe, just different. As both directions are therefore possible, the p-value is made up of the sum of the areas in the left and the right tails of the distribution. One-sided tests are possible, but generally in regression analysis the test is two-sided which is why I will leave it at that here.</p>
<div class="bulb">
<p><strong>Interpreting Significance Tests</strong></p>
<p>In these assessment, and when reporting statistical results more generally, you’ll be required to interpret the outcome of a significance test. To do this well, it’s important to use language that reflects what null hypothesis significance testing (NHST) actually tells us, without overstating what the test can conclude.</p>
<p>NHST works by starting with the null hypothesis - usually a claim like “there is no effect” or “there is no difference”. We use the data to test whether that assumption is plausible. If the p-value is small, it means that results as extreme as the one we observed — or more extreme — would be rare if the null hypothesis were true. So, we take that as evidence against the null. But if the p-value is large, then the data are consistent with the null. And that’s where your interpretation should stop (at least at the introductory level, to avoid stretching and overstating).</p>
<p>There are two possible outcomes of a significance test: (1) your p-value is <strong>below</strong> the required significance level, and (2) your p-value is <strong>above</strong> the required significance level. Let’s look at these in turn:</p>
<ol style="list-style-type: decimal">
<li>
<p>If your p-value is below the required significance level, you can say things like:</p>
<ul>
<li>“There is evidence of an effect.”</li>
<li>“We reject the null hypothesis.”</li>
<li>“The data provide evidence against the null hypothesis.”</li>
<li>“There is statistically significant evidence of a difference (or relationship, or effect).”</li>
</ul>
<p><span style="display:block; height: 0.5em;"></span></p>
<p>Avoid phrasing that implies certainty, such as:</p>
<ul>
<li>🚫 “We proved the alternative hypothesis.”</li>
<li>🚫 “We proved that there is an effect.”</li>
<li>🚫 “We accept the alternative hypothesis.”</li>
</ul>
</li>
</ol>
<p><span style="display:block; height: 0.1em;"></span></p>
<ol start="2" style="list-style-type: decimal">
<li>
<p>If your p-value is above the required significance level to reject the null hypothesis, you can say things like:</p>
<ul>
<li>“There is insufficient evidence for an effect (of a difference, for a relationship).”</li>
<li>“We cannot reject the null hypothesis.”</li>
<li>“We fail to reject the null hypothesis.”</li>
<li>“The results are consistent with the null hypothesis.”</li>
</ul>
<p><span style="display:block; height: 0.5em;"></span></p>
<p>Avoid phrasing that overstates what the test can tell you, such as:</p>
<ul>
<li>🚫 “We proved the null hypothesis.”</li>
<li>🚫 “We reject the alternative hypothesis.”</li>
<li>🚫 “The null hypothesis is true.”</li>
</ul>
</li>
</ol>
<p><span style="display:block; height: 0.1em;"></span></p>
<p>Having taught quantitative political analysis for many years, I know that students love to use the word “prove” when they interpret their results. But there is no proof in significance testing, because we deal with probability statements, not certainty.</p>
</div>
<p>And with that, we are finally ready to turn our attention to the actual topic for today: linear regression.</p>
</div>
</div>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    const buttons = document.querySelectorAll(".delayed-download");

    buttons.forEach(function (btn) {
      const releaseDate = new Date(btn.dataset.date);
      const now = new Date();

      if (now >= releaseDate) {
        btn.classList.remove("disabled");
        btn.setAttribute("aria-disabled", "false");
        btn.setAttribute("href", btn.dataset.path);
        btn.setAttribute("download", btn.dataset.path.split('/').pop());
        btn.innerHTML = btn.dataset.label || "📄 Download Document";
      }
    });
  });
</script><div class="chapter-nav">
<div class="prev"><a href="flashcards.html">Flashcards</a></div>
<div class="next"><a href="linear-regression---theory.html">Linear Regression - Theory</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#principles-of-statistical-inference">Principles of Statistical Inference</a></li>
<li>
<a class="nav-link" href="#probability-distributions">Probability Distributions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sampling-distributions">Sampling Distributions</a></li>
<li><a class="nav-link" href="#the-t-distribution">The t-Distribution</a></li>
</ul>
</li>
<li><a class="nav-link" href="#confidence-intervals">Confidence Intervals</a></li>
<li><a class="nav-link" href="#tests-of-statistical-significance">Tests of Statistical Significance</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong><p><img src="images/Crest_white.png" width="75" style="display:block; margin:auto; margin-bottom:3em;"> PO33Q: Determinants of Democracy – <br> Analysing Emergence, Survival, and Fall</p></strong>" was written by </p>
<p><strong>Dr Flo Reiche</strong> <br><strong>Department of Politics and International Studies</strong> <br><strong>University of Warwick</strong></p>. It was last built on 06 August, 2025.
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
